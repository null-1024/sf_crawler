# sf_crawler

crawler -> https://book.sfacg.com/

# 如何使用
- 没有难度, 只有一个参数id
- 例:https://book.sfacg.com/Novel/61423 *妖刀姬*的url, 其中61423就是书的id
- 在程序中批量下载, 只要修改range()的参数即可, 下载的书每本自动创建文件夹并有id序号 
